{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seqeval.metrics import accuracy_score\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers import BertForTokenClassification, AdamW\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p) for w, p in zip(s[\"Mot\"].values.tolist(),\n",
    "                                                           s[\"Label\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "\n",
    "class Bert_Model(object):\n",
    "    def __init__(self,sentences=[],labels=[],tag_values=[],tokenizer='bert-base-uncased'):\n",
    "        self.sentences=sentences\n",
    "        self.tag_values=tag_values\n",
    "        self.tag2idx={t: i for i, t in enumerate(self.tag_values)}\n",
    "        self.tokname=tokenizer\n",
    "        self.tokenizer=BertTokenizer.from_pretrained(tokenizer,do_lower_case=True)\n",
    "        self.labels=labels\n",
    "        self.MAX_LEN=512 #Si le modèle prends trop de temps réduire MAX_LEN, les phrases généralement ne sont pas composées de 512 mots\n",
    "        #Donc on peut se permettre de le diminuer et pour la prédiction de phrases longues, on split la phrase.\n",
    "        self.Nlabels=None\n",
    "        self.model=None\n",
    "\n",
    "    def getparam(self,MAX_LEN=512):\n",
    "        self.MAX_LEN=MAX_LEN\n",
    "\n",
    "    def getTag(self,tag_values):\n",
    "        self.tag_values=tag_values\n",
    "\n",
    "    def tokenize_and_preserve_labels(self,sentence,text_labels):\n",
    "        tokenized_sentence = []\n",
    "        labels = []\n",
    "\n",
    "        for word, label in zip(sentence, text_labels):\n",
    "\n",
    "            tokenized_word = self.tokenizer.tokenize(str(word))\n",
    "            n_subwords = len(tokenized_word)\n",
    "\n",
    "            tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "            labels.extend([label] * n_subwords)\n",
    "\n",
    "        return tokenized_sentence, labels\n",
    "    \n",
    "    def preprocess(self,random_state=100,test_size=0.1,bs=32,FULL_FINETUNING = True):\n",
    "        tokenized_texts_and_labels = [self.tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(self.sentences, self.labels) ]\n",
    "        tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "\n",
    "        self.Nlabels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n",
    "\n",
    "        self.input_ids = pad_sequences([self.tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                                maxlen=self.MAX_LEN, dtype=\"long\", value=0.0,\n",
    "                                truncating=\"post\", padding=\"post\")\n",
    "\n",
    "        self.tags = pad_sequences([[self.tag2idx.get(l) for l in lab] for lab in self.Nlabels],\n",
    "                            maxlen=self.MAX_LEN, value=self.tag2idx[\"PAD\"], padding=\"post\",\n",
    "                            dtype=\"long\", truncating=\"post\")\n",
    "\n",
    "        self.attention_masks = [[float(i != 0.0) for i in ii] for ii in self.input_ids]\n",
    "        tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(self.input_ids, self.tags,\n",
    "                                                            random_state=random_state, test_size=test_size)\n",
    "        tr_masks, val_masks, _, _ = train_test_split(self.attention_masks, self.input_ids,\n",
    "                                             random_state=random_state, test_size=test_size)\n",
    "        tr_inputs = torch.tensor(tr_inputs)\n",
    "        val_inputs = torch.tensor(val_inputs)\n",
    "        tr_tags = torch.tensor(tr_tags)\n",
    "        val_tags = torch.tensor(val_tags)\n",
    "        tr_masks = torch.tensor(tr_masks)\n",
    "        val_masks = torch.tensor(val_masks)\n",
    "        self.train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "        self.train_sampler = RandomSampler(self.train_data)\n",
    "        self.train_dataloader = DataLoader(self.train_data, sampler=self.train_sampler, batch_size=bs)\n",
    "\n",
    "        self.valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "        self.valid_sampler = SequentialSampler(self.valid_data)\n",
    "        self.valid_dataloader = DataLoader(self.valid_data, sampler=self.valid_sampler, batch_size=bs)\n",
    "        self.model = BertForTokenClassification.from_pretrained(\n",
    "                self.tokname,\n",
    "                num_labels=len(self.tag2idx),\n",
    "                output_attentions = False,\n",
    "                output_hidden_states = False)\n",
    "        if FULL_FINETUNING:\n",
    "            param_optimizer = list(self.model.named_parameters())\n",
    "            no_decay = ['bias', 'gamma', 'beta']\n",
    "            optimizer_grouped_parameters = [\n",
    "                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay_rate': 0.01},\n",
    "                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay_rate': 0.0}]\n",
    "        else:\n",
    "            param_optimizer = list(self.model.classifier.named_parameters())\n",
    "            optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "        self.optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=3e-5,\n",
    "            eps=1e-8)\n",
    "        \n",
    "    def train_eval(self,epochs=1,max_grad_norm = 1.0,weight=[1,1,1],currloss=np.inf,path='./outputsNSD/modeleNSD'):\n",
    "        #args.overwrite_output_dir =True\n",
    "\n",
    "        total_steps = len(self.train_dataloader) * epochs\n",
    "        class_weights=torch.tensor(weight,dtype=torch.float)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        loss_values, validation_loss_values = [], []\n",
    "\n",
    "        for _ in trange(epochs, desc=\"Epoch\"):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "\n",
    "            for step, batch in enumerate(self.train_dataloader):\n",
    "\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "                self.model.zero_grad()\n",
    "\n",
    "                outputs = self.model(b_input_ids.long(), token_type_ids=None,\n",
    "                                attention_mask=b_input_mask, labels=b_labels.long())\n",
    "                \n",
    "                loss = outputs[0]\n",
    "                scores = outputs.logits\n",
    "                targets = b_labels[:, :scores.shape[1]] \n",
    "                loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "                loss = loss_fn(scores.view(-1, scores.shape[-1]), targets.view(-1).long())       \n",
    "                loss.backward()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(parameters=self.model.parameters(), max_norm=max_grad_norm)\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "            \n",
    "            avg_train_loss = total_loss / len(self.train_dataloader)\n",
    "            print(\"Average train loss: {}\".format(avg_train_loss))\n",
    "\n",
    "            loss_values.append(avg_train_loss)\n",
    "\n",
    "            #Evaluation du modèle\n",
    "            self.model.eval()\n",
    "            \n",
    "            eval_loss, eval_accuracy = 0, 0\n",
    "            nb_eval_steps, nb_eval_examples = 0, 0\n",
    "            predictions , true_labels = [], []\n",
    "            for batch in self.valid_dataloader:\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    outputs = self.model(b_input_ids.long(), token_type_ids=None,\n",
    "                                    attention_mask=b_input_mask, labels=b_labels.long())\n",
    "                \n",
    "                logits = outputs[1].detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "                \n",
    "                eval_loss += outputs[0].mean().item()\n",
    "                predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "                true_labels.extend(label_ids)\n",
    "\n",
    "            eval_loss = eval_loss / len(self.valid_dataloader)\n",
    "            validation_loss_values.append(eval_loss)\n",
    "            #print(len(predictions),len(true_labels))\n",
    "            print(\"Validation loss: {}\".format(eval_loss))\n",
    "            pred_tags = [self.tag_values[p_i] for p, l in zip(predictions, true_labels)\n",
    "                                        for p_i, l_i in zip(p, l) if self.tag_values[l_i] != \"PAD\"]\n",
    "            valid_tags = [self.tag_values[l_i] for l in true_labels\n",
    "                                        for l_i in l if self.tag_values[l_i] != \"PAD\"]\n",
    "            print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n",
    "            print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags,average='weighted')))\n",
    "            classification_rep = classification_report(valid_tags, pred_tags)\n",
    "            print(\"Classification Report:\\n\", classification_rep)\n",
    "            print()\n",
    "            #self.model.save_pretrained('./outputs/modeleFT')\n",
    "            self.loss_values=loss_values\n",
    "            self.validation_loss_values=validation_loss_values\n",
    "            if currloss>eval_loss:\n",
    "                self.save_model(path)\n",
    "                print(\"Model saved successfully.\")\n",
    "                currloss=eval_loss\n",
    "\n",
    "    def save_model(self, path):\n",
    "            self.model.save_pretrained(path)\n",
    "            self.tokenizer.save_pretrained(path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "            self.model = BertForTokenClassification.from_pretrained(path)\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(path)\n",
    "            self.model.eval()\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "        torch.cuda.empty_cache()\n",
    "        #self.model.cuda()\n",
    "        self.model.eval()\n",
    "        tokenized_sentence = self.tokenizer.tokenize(sentence)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "        attention_mask = [[float(i != 0.0) for i in tokens_tensor[0]]]\n",
    "        attention_mask = torch.tensor(attention_mask).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor, token_type_ids=None, attention_mask=attention_mask)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_indices = np.argmax(logits, axis=2)[0]\n",
    "        labels = [self.tag_values[label_idx] for label_idx in label_indices]\n",
    "        return list(zip(tokenized_sentence, labels))\n",
    "    \n",
    "\n",
    "    def batch_predict(self, sentences):\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            predictions = list(executor.map(self.predict, sentences))\n",
    "        return predictions    \n",
    "\n",
    "\n",
    "                \n",
    "    def plotloss(self):\n",
    "        sns.set(style='darkgrid')\n",
    "\n",
    "        sns.set(font_scale=1.5)\n",
    "        plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "        plt.plot(self.loss_values, 'b-o', label=\"training loss\")\n",
    "        plt.plot(self.validation_loss_values, 'r-o', label=\"validation loss\")\n",
    "\n",
    "        plt.title(\"Learning curve\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def convert2cue(oui,sentence):\n",
    "    \"\"\" Applique le modèle de cue detection au phrases d'entrée pour transformer les mots labellisés cue en [CUE]\"\"\"\n",
    "    new_sentence=[]\n",
    "    for sen in sentence:\n",
    "        test_sentence=[x.lower() for x in sen]\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        n_gpu = torch.cuda.device_count()\n",
    "        tokenized_sentence = oui.tokenizer.encode(test_sentence)\n",
    "        input_ids = torch.tensor([tokenized_sentence])\n",
    "        with torch.no_grad():\n",
    "            output = oui.model(input_ids)\n",
    "        label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "\n",
    "        tokens = oui.tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "        new_tokens, new_labels = [], []\n",
    "        for token, label_idx in zip(tokens, label_indices[0]):\n",
    "            if token.startswith(\"##\"):\n",
    "                new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "            else:\n",
    "                new_labels.append(oui.tag_values[label_idx])\n",
    "                new_tokens.append(token)\n",
    "        #print(list(map(lambda x, y: '[CUE]' if x == 'CUE' else y, new_labels[1:-1], test_sentence)))\n",
    "        new_sentence.append(list(map(lambda x, y: '[CUE]' if x == 'CUE' else y, new_labels[1:-1], test_sentence)))\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-Mood': 0,\n",
       " 'O': 1,\n",
       " 'B-Drug': 2,\n",
       " 'I-Procedure': 3,\n",
       " 'B-Condition': 4,\n",
       " 'B-Person': 5,\n",
       " 'I-Condition': 6,\n",
       " 'B-Procedure': 7,\n",
       " 'B-Observation': 8,\n",
       " 'I-Drug': 9,\n",
       " 'I-Observation': 10,\n",
       " 'I-Person': 11,\n",
       " 'I-Mood': 12,\n",
       " 'PAD': 13}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tag_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30351/2102769662.py:2: DtypeWarning: Columns (2,3,4,5,10,11,12,13,14,15,17,18,19,21,22,23,24,25,26,28,29,30,31,32,33,34,35,36,37,42,43,68,79,80,81,82,88,89,94,95,97,98,99,100,101,102,104,105,109,110,111,112,113,114,115,116,118,121,122,151,163,169,184,192,193,194,195,196,200,206,209,210,212,213,214,215,216,217,218,219,220,222,223,225,226,228,229,230,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,262,263,264,265,266,275,279,280,282,283,284,285,286,287,300,301,302,303,304,308,320,321,322,324,325,326) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/clini_data.csv')\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train.csv').head(5000)\n",
    "df = pd.read_csv('../data/clini_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['With',\n",
       " 'severe',\n",
       " 'comorbidities',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'cardiovascular',\n",
       " 'disease',\n",
       " ',',\n",
       " 'chronic',\n",
       " 'obstructive',\n",
       " 'pulmonary',\n",
       " 'disease',\n",
       " ',',\n",
       " 'diabetes',\n",
       " 'mellitus',\n",
       " ',',\n",
       " 'and',\n",
       " 'chronic',\n",
       " 'renal',\n",
       " 'dysfunction',\n",
       " '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [[word[0] for word in sentence] for sentence in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-Condition', 'O', 'O', 'O', 'B-Condition', 'I-Condition', 'O', 'B-Condition', 'I-Condition', 'I-Condition', 'I-Condition', 'O', 'B-Condition', 'I-Condition', 'O', 'O', 'B-Condition', 'I-Condition', 'I-Condition', 'O']\n"
     ]
    }
   ],
   "source": [
    "labels = [[s[1] for s in sentence] for sentence in getter.sentences]\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-Mood': 0,\n",
       " 'O': 1,\n",
       " 'B-Drug': 2,\n",
       " 'I-Procedure': 3,\n",
       " 'B-Condition': 4,\n",
       " 'B-Person': 5,\n",
       " 'I-Condition': 6,\n",
       " 'B-Procedure': 7,\n",
       " 'B-Observation': 8,\n",
       " 'I-Drug': 9,\n",
       " 'I-Observation': 10,\n",
       " 'I-Person': 11,\n",
       " 'I-Mood': 12,\n",
       " 'PAD': 13}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_values = list(set(df_train[\"Label\"].values))\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bert_Model(sentences=sentences, labels=labels, tag_values=tag_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.getparam(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/onyxia/work/.venv/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1]*len(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: 1.2004535396893818\n",
      "Validation loss: 0.6252216100692749\n",
      "Validation Accuracy: 0.0016155088852988692\n",
      "Validation F1-Score: 8.138583805032086e-06\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  B-Condition       0.00      0.00      0.00        59\n",
      "       B-Drug       0.00      0.00      0.00        25\n",
      "       B-Mood       0.00      0.00      0.00         9\n",
      "B-Observation       0.00      0.00      0.00         1\n",
      "     B-Person       0.00      0.00      0.00         9\n",
      "  B-Procedure       0.00      0.00      0.00        11\n",
      "  I-Condition       0.00      0.00      0.00        71\n",
      "       I-Drug       0.00      0.00      0.00        10\n",
      "       I-Mood       0.00      0.00      0.00         5\n",
      "     I-Person       0.00      0.00      0.00         4\n",
      "  I-Procedure       0.00      0.00      0.00        19\n",
      "            O       1.00      0.00      0.01       396\n",
      "          PAD       0.00      0.00      0.00         0\n",
      "\n",
      "     accuracy                           0.00       619\n",
      "    macro avg       0.08      0.00      0.00       619\n",
      " weighted avg       0.64      0.00      0.00       619\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/onyxia/work/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/onyxia/work/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/onyxia/work/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/onyxia/work/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/onyxia/work/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Epoch: 100%|██████████| 1/1 [02:09<00:00, 129.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train_eval(weight=[1]*len(tag2idx))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
